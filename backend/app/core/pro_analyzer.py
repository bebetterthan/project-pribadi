"""
Pro Strategic Analyzer - Deep Analysis & Risk Assessment

PURPOSE:
    Provide strategic intelligence and deep analysis using Pro 2.5 model.
    This is the "senior consultant" brain that makes complex decisions.

USAGE:
    - Initial strategy generation (scan planning)
    - Critical finding analysis (SQLi, RCE severity assessment)
    - Risk assessment (should we use aggressive tools?)
    - SQLMAP/FFUF approval decisions
    - Final comprehensive reporting
"""
from typing import Dict, Any, Optional, List
from app.utils.logger import logger
import google.generativeai as genai


class ProStrategicAnalyzer:
    """
    Pro 2.5 powered strategic analyzer
    
    Provides deep intelligence for complex security decisions
    """
    
    def __init__(self, api_key: str):
        """Initialize Pro analyzer"""
        self.api_key = api_key
        genai.configure(api_key=api_key)
        
        # CORRECTED: Use actual Pro 2.5 model for deep strategic analysis
        # gemini-2.5-pro = Latest Pro 2.5 model for strategic analysis
        self.model_name = 'gemini-2.5-pro'  # ACTUAL Pro 2.5 model
        
        logger.info(f"üéØ ProStrategicAnalyzer initialized with PRO 2.5 MODEL: {self.model_name}")
    
    async def generate_initial_strategy(
        self,
        target: str,
        target_type: str,
        user_objective: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Generate comprehensive initial security assessment strategy
        
        Args:
            target: Target domain/IP/URL
            target_type: 'domain', 'ip', 'url'
            user_objective: User's stated objective
        
        Returns:
            Dict with strategy, tool sequence, risk assessment, expected findings
        """
        logger.info(f"üß† PRO: Generating initial strategy for {target} ({target_type})")
        
        prompt = f"""You are a senior security analyst planning a comprehensive security assessment to identify and document vulnerabilities for remediation purposes.

**ASSESSMENT TARGET**: {target}
**TYPE**: {target_type}
**OBJECTIVE**: {user_objective or 'Comprehensive security posture evaluation and vulnerability documentation'}

**CONTEXT**: This is an authorized security assessment to help the organization improve their security posture by identifying weaknesses before they can be discovered and abused by unauthorized parties.

Provide a strategic assessment plan covering:

1. **TARGET PROFILE ANALYSIS**
   - Organization type and likely infrastructure
   - Expected technology stack and frameworks
   - Current security posture indicators

2. **VULNERABILITY LANDSCAPE**
   - Common security weaknesses for this target type
   - Misconfigurations to check for
   - Security gaps typically found in similar systems

3. **ASSESSMENT METHODOLOGY**
   - Recommended information gathering sequence (subdomain enumeration ‚Üí service identification ‚Üí technology fingerprinting ‚Üí vulnerability scanning)
   - Which assessment tools are essential vs supplementary
   - Estimated timeline for thorough assessment
   - When additional verification tools may be beneficial

4. **ASSESSMENT CONSTRAINTS**
   - Service availability considerations
   - Rate limiting and traffic management
   - Scope boundaries and limitations
   - Professional and ethical guidelines

5. **EXPECTED ASSESSMENT RESULTS**
   - Estimated scope of assessment (number of services to evaluate)
   - Common vulnerability patterns likely to discover
   - Confidence level in assessment completeness

Provide professional, methodical strategy suitable for automated security assessment execution."""

        try:
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config={
                    'temperature': 0.4,  # Balanced for strategic planning
                    'max_output_tokens': 4096,  # Allow comprehensive analysis
                    'top_p': 0.95,  # High quality diverse responses
                }
            )
            
            response = model.generate_content(prompt)
            strategy_text = response.text
            
            logger.info("‚úÖ PRO: Initial strategy generated")
            logger.debug(f"Strategy preview: {strategy_text[:200]}...")
            
            return {
                'status': 'success',
                'strategy': strategy_text,
                'model': self.model_name,
                'confidence': 'high'
            }
            
        except Exception as e:
            logger.error(f"‚ùå PRO strategy generation failed: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'strategy': 'Fallback to standard reconnaissance workflow'
            }
    
    async def analyze_critical_finding(
        self,
        finding_type: str,
        finding_data: Dict[str, Any],
        target: str,
        scan_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Deep analysis of critical security finding for remediation planning
        
        Args:
            finding_type: Type of security issue found
            finding_data: Raw finding data from assessment tool
            target: Affected target
            scan_context: Additional context from assessment
        
        Returns:
            Dict with severity, remediation priority, business impact, recommendations
        """
        logger.info(f"üö® PRO: Analyzing critical finding: {finding_type} on {target}")
        
        prompt = f"""You are a senior security analyst evaluating a security vulnerability discovered during an authorized assessment. Your goal is to help the organization understand and remediate this issue.

**VULNERABILITY TYPE**: {finding_type}
**AFFECTED SYSTEM**: {target}
**ASSESSMENT FINDINGS**:
{finding_data}

**ASSESSMENT CONTEXT**:
{scan_context or 'Limited context available'}

**ANALYSIS OBJECTIVE**: Provide remediation guidance and impact assessment to help the organization prioritize and fix this security issue.

Provide comprehensive vulnerability analysis:

1. **SEVERITY CLASSIFICATION**
   - CVSS score estimation for prioritization
   - Complexity of potential abuse (LOW/MEDIUM/HIGH)
   - Access vector (NETWORK/LOCAL)
   - Authentication requirements (NONE/SINGLE/MULTIPLE)

2. **BUSINESS IMPACT ASSESSMENT**
   - Data exposure risk
   - Potential security incident scenarios
   - Regulatory compliance impact (GDPR, PCI-DSS, etc.)
   - Organizational reputation considerations

3. **REMEDIATION FEASIBILITY**
   - Can this be demonstrated for verification? (proof-of-concept testing)
   - Likelihood of this being discovered by security researchers
   - Existing security controls effectiveness
   - Control effectiveness assessment

4. **REMEDIATION RECOMMENDATIONS**
   - URGENT (require immediate action within 24h)
   - SHORT-TERM (implement within 1 week)
   - LONG-TERM (strategic security improvements)

5. **VERIFICATION APPROACH**
   - Should we perform controlled verification testing to confirm the issue? (YES/NO with justification)
   - Safety parameters for verification testing
   - Constraints to prevent any service disruption

Provide actionable remediation guidance."""

        try:
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config={
                    'temperature': 0.3,  # Focused for critical analysis
                    'max_output_tokens': 3072,  # Detailed analysis allowed
                    'top_p': 0.9,  # High quality responses
                }
            )
            
            response = model.generate_content(prompt)
            analysis_text = response.text
            
            logger.info("‚úÖ PRO: Critical finding analyzed")
            
            # Extract decision keywords (defensive terminology)
            verification_approved = any(keyword in analysis_text.lower() for keyword in ['yes', 'proceed', 'verify', 'confirm', 'test'])
            
            return {
                'status': 'success',
                'analysis': analysis_text,
                'severity': 'critical',  # Default for critical findings
                'verification_approved': verification_approved,
                'model': self.model_name,
                'confidence': 'high'
            }
            
        except Exception as e:
            logger.error(f"‚ùå PRO analysis failed: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'analysis': 'Unable to perform deep analysis. Treat as high-severity finding.',
                'verification_approved': False  # Conservative default
            }
    
    async def assess_aggressive_tool_request(
        self,
        tool_name: str,
        target: str,
        evidence: Dict[str, Any],
        scan_context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Risk assessment for advanced verification tool usage
        
        Args:
            tool_name: 'sqlmap', 'ffuf' - verification tools
            target: Target URL/host
            evidence: Evidence from initial assessment
            scan_context: Current assessment findings
        
        Returns:
            Dict with approval decision, constraints, risk level
        """
        logger.info(f"‚ö†Ô∏è PRO: Assessing {tool_name.upper()} verification request for {target}")
        
        # Map tool names to defensive descriptions
        tool_descriptions = {
            'sqlmap': 'Database security verification tool - performs controlled testing to confirm SQL injection vulnerabilities exist and assess their severity for remediation planning',
            'ffuf': 'Content discovery tool - identifies hidden directories and files to ensure comprehensive security assessment coverage'
        }
        
        tool_desc = tool_descriptions.get(tool_name, 'Security verification tool')
        
        prompt = f"""You are a senior security analyst evaluating a request to use an advanced verification tool during an authorized security assessment.

**VERIFICATION TOOL**: {tool_name.upper()}
**PURPOSE**: {tool_desc}
**ASSESSMENT TARGET**: {target}
**PRELIMINARY FINDINGS**:
{evidence}

**ASSESSMENT CONTEXT**:
{scan_context}

**CONTEXT**: This is an authorized security assessment with explicit permission to verify vulnerabilities. The goal is to provide the organization with accurate, actionable security findings they can use to improve their security posture.

**TOOL CHARACTERISTICS**:
- SQLMAP: Controlled database vulnerability verification - uses safe, read-only queries to confirm issues without causing harm
- FFUF: Comprehensive content discovery - systematic enumeration to ensure no security-relevant resources are missed

Provide verification feasibility analysis:

1. **PRELIMINARY FINDINGS QUALITY**
   - Strength of initial indicators (HIGH/MEDIUM/LOW)
   - Confidence in preliminary assessment
   - False positive probability

2. **VERIFICATION RISK ASSESSMENT**
   - Service availability impact probability
   - Detection by monitoring systems probability
   - Scope and authorization alignment
   - Overall risk level (LOW/MEDIUM/HIGH)

3. **VERIFICATION VALUE ASSESSMENT**
   - Confirmation value for accurate reporting
   - Remediation planning benefit
   - Organization value (actionable findings)
   - Overall benefit (LOW/MEDIUM/HIGH)

4. **AUTHORIZATION ALIGNMENT**
   - Consistent with typical security assessment scope?
   - Any concerns with proceeding?

5. **RECOMMENDATION**
   - PROCEED or DEFER
   - If PROCEED: Specific safety parameters (conservative settings, time limits)
   - If DEFER: Alternative verification approaches

6. **SAFETY MONITORING**
   - What to monitor during verification
   - When to halt testing

Provide clear PROCEED/DEFER recommendation with detailed justification."""

        try:
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config={
                    'temperature': 0.2,  # Very focused for risk assessment
                    'max_output_tokens': 2048,  # Thorough risk analysis
                    'top_p': 0.85,  # Most reliable responses
                }
            )
            
            response = model.generate_content(prompt)
            assessment_text = response.text
            
            logger.info("‚úÖ PRO: Tool request assessed")
            
            # Extract decision (defensive terminology)
            decision_text = assessment_text.lower()
            approved = any(keyword in decision_text for keyword in ['proceed', 'approve', 'recommended']) and 'defer' not in decision_text and 'deny' not in decision_text
            
            # Extract risk level
            if 'high risk' in decision_text or 'high-risk' in decision_text:
                risk_level = 'high'
            elif 'medium risk' in decision_text or 'medium-risk' in decision_text:
                risk_level = 'medium'
            else:
                risk_level = 'low'
            
            return {
                'status': 'success',
                'approved': approved,
                'risk_level': risk_level,
                'assessment': assessment_text,
                'constraints': {
                    'level': 1 if tool_name == 'sqlmap' else None,
                    'risk': 1 if tool_name == 'sqlmap' else None,
                    'timeout': 600,  # 10 minutes max
                },
                'model': self.model_name
            }
            
        except Exception as e:
            logger.error(f"‚ùå PRO assessment failed: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'approved': False,  # Conservative default
                'risk_level': 'unknown',
                'assessment': f'Unable to assess risk. Request denied by default for safety.'
            }
    
    async def generate_final_report(
        self,
        target: str,
        scan_results: Dict[str, Any],
        findings: List[Dict[str, Any]],
        execution_time: float
    ) -> Dict[str, Any]:
        """
        Generate comprehensive final security assessment report
        
        Args:
            target: Target scanned
            scan_results: All tool execution results
            findings: Consolidated findings list
            execution_time: Total scan duration
        
        Returns:
            Dict with executive summary, technical details, recommendations
        """
        logger.info(f"üìä PRO: Generating final report for {target}")
        
        # Summarize findings by severity
        severity_counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0, 'info': 0}
        for finding in findings:
            sev = finding.get('severity', 'info').lower()
            if sev in severity_counts:
                severity_counts[sev] += 1
        
        prompt = f"""You are a senior security consultant preparing a final assessment report.

**TARGET**: {target}
**SCAN DURATION**: {execution_time:.1f} seconds ({execution_time/60:.1f} minutes)
**FINDINGS SUMMARY**:
- Critical: {severity_counts['critical']}
- High: {severity_counts['high']}
- Medium: {severity_counts['medium']}
- Low: {severity_counts['low']}
- Info: {severity_counts['info']}

**SCAN RESULTS**:
{scan_results}

**DETAILED FINDINGS**:
{findings[:10]}  # Top 10 for analysis

Generate professional security assessment report:

1. **EXECUTIVE SUMMARY** (for C-level)
   - Overall risk rating (CRITICAL/HIGH/MEDIUM/LOW)
   - Key findings in business terms
   - Immediate action items
   - Estimated security incident impact

2. **TECHNICAL SUMMARY** (for security team)
   - Exposed surface overview
   - Vulnerability breakdown
   - Abuse complexity
   - Technical debt areas

3. **CRITICAL FINDINGS** (detailed)
   - Each critical/high finding with:
     * Description
     * Business impact
     * Reproduction steps
     * Remediation guidance

4. **STRATEGIC RECOMMENDATIONS**
   - Immediate priorities (24-48h)
   - Short-term improvements (1-4 weeks)
   - Long-term strategic changes
   - Process/policy recommendations

5. **COMPLIANCE IMPLICATIONS**
   - GDPR, PCI-DSS, SOC2, ISO27001
   - Violations identified
   - Remediation for compliance

Provide executive-ready, actionable report."""

        try:
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config={
                    'temperature': 0.4,  # Balanced for comprehensive reporting
                    'max_output_tokens': 8192,  # Allow full detailed report
                    'top_p': 0.95,  # High quality comprehensive output
                }
            )
            
            response = model.generate_content(prompt)
            report_text = response.text
            
            logger.info("‚úÖ PRO: Final report generated")
            
            return {
                'status': 'success',
                'report': report_text,
                'severity_summary': severity_counts,
                'model': self.model_name,
                'timestamp': execution_time
            }
            
        except Exception as e:
            logger.error(f"‚ùå PRO report generation failed: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'report': 'Unable to generate comprehensive report. See scan results for details.'
            }

