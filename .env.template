# Agent-P Environment Configuration Template
# Copy this file to .env and fill in your values

#==============================================================================
# Core Application Settings
#==============================================================================

# Application environment (development, staging, production)
ENVIRONMENT=development

# Database configuration
DATABASE_URL=sqlite:///./pentest.db

# API Security
SECRET_KEY=your-secret-key-here-change-in-production
API_KEY=your-api-key-here

#==============================================================================
# AI Integration Settings (Ollama + Qwen)
#==============================================================================

# Ollama Service Configuration
# The public HTTPS endpoint for Ollama service on GitHub Codespaces
# Default points to the Codespaces forwarded port
OLLAMA_URL=https://zany-acorn-v6jqg9w5qw4w3r4w-11434.app.github.dev

# Ollama Model Selection
# Model identifier for Qwen 2.5 14B (already downloaded in Codespaces)
# Available models: qwen2.5:14b, qwen2.5:7b, qwen2.5:1.5b
OLLAMA_MODEL=qwen2.5:14b

# Ollama Request Timeout
# Maximum seconds to wait for AI response (10-120 recommended)
# Longer timeouts for complex strategic analysis, shorter for quick queries
OLLAMA_TIMEOUT=30

# AI Integration Control
# Set to 'false' to disable AI features entirely (Agent-P works without AI)
# Useful for testing, debugging, or when Ollama unavailable
ENABLE_AI_INTEGRATION=true

#==============================================================================
# Intelligence Router Settings
#==============================================================================

# Strategic Analysis Thresholds
# These control when AI reasoning is triggered vs simple tactical logic

# Subdomain count threshold for strategic planning
# When discovered subdomains >= this value, trigger AI strategic planning
# Recommended: 100 (adjust based on typical target complexity)
QWEN_TRIGGER_SUBDOMAIN_COUNT=100

# Vulnerability finding threshold for AI prioritization
# When findings >= this value, use AI for risk-based prioritization
# Recommended: 20 (adjust based on typical scan results)
QWEN_TRIGGER_FINDING_COUNT=20

# Response Caching
# Cache AI responses to avoid redundant queries for same prompts
# Recommended: true (improves performance, reduces API calls)
ENABLE_RESPONSE_CACHE=true

#==============================================================================
# Security Scanning Settings
#==============================================================================

# Tool Execution Configuration
MAX_CONCURRENT_TOOL_EXECUTIONS=3
NMAP_TIMEOUT=300
SUBFINDER_TIMEOUT=120
NUCLEI_TIMEOUT=600

# Scan result retention
SCAN_HISTORY_DAYS=30

#==============================================================================
# Logging Configuration
#==============================================================================

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# DEBUG: Detailed routing decisions and AI interactions
# INFO: Major milestones and AI usage
# WARNING: Issues that don't stop execution
# ERROR: Failures requiring attention
LOG_LEVEL=INFO

# Log file location
LOG_FILE=backend/logs/app.log

# Log rotation
LOG_MAX_BYTES=10485760  # 10MB
LOG_BACKUP_COUNT=5

#==============================================================================
# Frontend Configuration
#==============================================================================

# Frontend URL for CORS
FRONTEND_URL=http://localhost:3000

# API Base URL
API_BASE_URL=http://localhost:8000

#==============================================================================
# Optional: Alternative AI Providers (Future Support)
#==============================================================================

# Google Gemini API (if using cloud-based AI instead of Ollama)
# GEMINI_API_KEY=your-gemini-api-key-here
# GEMINI_MODEL=gemini-2.0-flash-exp

# OpenAI API (future support)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_MODEL=gpt-4

#==============================================================================
# Development Settings
#==============================================================================

# Enable debug mode (DO NOT USE IN PRODUCTION)
DEBUG=false

# Enable API documentation
ENABLE_DOCS=true

# Reload on code changes
RELOAD_ON_CHANGE=true

#==============================================================================
# Notes
#==============================================================================

# AI Integration Philosophy:
# - Agent-P works normally when ENABLE_AI_INTEGRATION=false
# - AI adds strategic intelligence but is optional
# - Thresholds control when AI vs tactical logic used
# - All AI failures handled gracefully with fallbacks
#
# For Codespaces Setup:
# 1. Run ./startup_ollama.sh to start Ollama service
# 2. Verify OLLAMA_URL matches your Codespaces forwarded port
# 3. Ensure port 11434 visibility set to "Public" in Codespaces
# 4. Test with: curl $OLLAMA_URL/api/version
#
# Performance Tips:
# - Lower OLLAMA_TIMEOUT for faster failures (but may miss slow responses)
# - Increase thresholds to use AI less frequently (faster scans)
# - Decrease thresholds to use AI more often (better analysis)
# - Enable cache for repeated queries (ENABLE_RESPONSE_CACHE=true)
